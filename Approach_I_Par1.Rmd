---
title: "Approach I"
author: "Astha Bista"
date: "2/9/2021"
output: md_document
bibliography: [packages.bib, ref.bib]
biblio-style: "apalike"
link-citations: true
---
This document consists of two main parts of Approach I: Principal component analysis and cluster analysis. The data used were firsk made stationary by using first degree differencing.
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r  warning=FALSE,, include=FALSE, echo=FALSE}
setwd("C:/Users/Aastha/Desktop/GWProject")
list.of.packages <- c("tseries","FactoMineR","factoextra","rela","psych","corrplot","NbClust")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library("FactoMineR")
library("factoextra")
library(rela)
library(psych)
library(corrplot)
library(tseries)
library(NbClust)
```
Before beginning, here is a function to plot many time series using ggplot.We will be using this function in the following lines to plot stationary time series.

```{r}
create_timeseries_plots <- function(df){
  # change into metres
  df <- sapply(as.data.frame(df), function(y) y*0.3048)
  # column with dates
  dates = seq(from = as.Date("2000-02-01"), to = as.Date("2018-12-1"), by = 'month') 
  # add date column to dataframe
  df_m <- data.frame(as.data.frame(df[,-1]),dates)
  colnames(df_m)[ncol(df_m)]<-"Date"
  library(reshape2)
  library(ggplot2)
  library(dplyr)
  # Rearrange dataframe to long form
  df_m2 <- melt(df_m, id.vars = "Date", 
                variable.name = "Var", value.name="Val")
  # Group the dataframe
  df_m3 <- df_m2%>%
    group_by(Date,Var)
  #Plot using ggplot2
  ggplot(data = df_m3,aes(x = Date, y = Val)) + 
    geom_line() + facet_wrap(~ Var, nrow = 6, scales = "free") +
    xlab("Year") + ylab("Units(m)") + theme_bw()
}

```


# Converting time series to stationary
In this approach, the time series data is made stationary using first differencing methods. For testing stationarity, Augmented Dickey-Fuller (ADF) t-statistic test for unit root was used.

```{r warning=FALSE}
GWData<-read.csv(file ="Data_Processing/GWLevel_imputed.csv",header = TRUE)  
head(GWData)
```
Now, loop around each column in the dataframe to obtain a dataframe containing first degree differenced values.

```{r warning=FALSE,include=FALSE}
diff_gw<-c()
for(i in 2:13){               #Loop around 13 wells groundwater levels
  diff_dat<-diff(GWData[,i])    #First degree differencing
  diff_gw<-cbind(diff_gw,diff_dat)
}

colnames(diff_gw)<-c("W60","W63","W67","W70","W73","W74","W78","W80","W81","W115","W116","W118")

# Check stationarity of each column in new dataframe using Augmented Dickey-Fuller (ADF) 
# t-statistic test for unit root. If H0 is rejected, the series is stationary
for(i in 1:12){ 
  print(adf.test(diff_gw[,i])$p.value)  #Alternate hypotheisis: stationary
}
```
This above procedure were also used to create stationary time series of stream stage, precipitation, and pumping.
Below is the plot showing the stationary time series. Please note that the units are differences of water levels between a month and preceding month, therefore the negative values in some cases.
```{r  fig.height=10,fig.width=10, warning=FALSE}
create_timeseries_plots(diff_gw)
```

# Principal Component Analysis

### Check suitability of PCA
```{r }
#First compute correlation matrix
GWDataCor <- cor(GWData)
```

We now examine the data to assess whether the assumptions for PCA have been met before proceeding. For this, instructions from [@field2012discovering] were used. We use the paf() function from the rela package [@R-rela].
```{r  include=FALSE}
assumptions <- paf(as.matrix(GWData), eigcrit = 1, convcrit = .001)
```

To test for the first assumption, Bartlett’s Test for Sphericity was performed. The null hypothesis for this test is that the intercorrelation matrix comes from a noncollinear populaton or simply that there is nocollinearity between the variables, which would render PCA impossible as it depends on the construction of a linear combination of the variables. We use a significance level α=.05.
```{r ,warning=FALSE}
bartlettTest <- cortest.bartlett(GWDataCor)
bartlettTest
```

Bartlett test is rejected because p values is less than 0.01. Now we will extract Kaiser-Meyer-Olkin (KMO) from the assumptions object.
```{r }
print(assumptions$KMO)
```

This value is more than 0.7, so can be acceptable. 
```{r}
det(GWDataCor)
```
The determinant is positive, hence it satisfies all three assumptions of PCA. Therefore, we can proceed with PCA.

### Analyzing correlation matrix
The correlation matrix is shown graphically. This following plot gives a prelimminary insight on the relationship between the groundwater levels in wells.
```{r}
cor.mat <- round(cor(GWData),2)
corrplot(cor.mat, type="upper", order="hclust", 
         tl.col="black", tl.srt=45)
```

### Performing PCA
PCA analysis operation was followed step by step from [@kassambara2017practical] and [link](http://www.sthda.com/english/wiki/print.php?id=202). The data is first standardized by centering and scaling.
```{r}
GWData<-scale(GWData)
```
Now, FactoMine package [@FactoMineR2008] is used to perform PCA.
```{r}
res.pca <- PCA(GWData, graph = F)
```
```{r echo=FALSE}
eigenvalues <- res.pca$eig
barplot(eigenvalues[, 2], names.arg=1:nrow(eigenvalues), 
        main = "Variances",
        xlab = "Principal Components",
        ylab = "Percentage of variances",
        col ="steelblue")
lines(x = 1:nrow(eigenvalues), eigenvalues[, 2], 
      type="b", pch=19, col = "red")
```

The above screeplot shows that three components are dominant in the data. Therefore, we will use three principal components. The variables can also be shown in a base graph showing contribution levels of each well along with information on the alignment of each well on principal components.
```{r }
fviz_pca_var(res.pca, col.var="contrib")+ 
  scale_color_gradient2(low="white",mid="blue",high="red", midpoint=2.5)+theme_bw()
```

### Output
The main output of PCA are PC scores and PC loadings.
```{r }
loadings<-sweep(res.pca$var$coord,2,sqrt(res.pca$eig[1:ncol(res.pca$var$coord),1]),FUN="/")
scores <- res.pca$ind$coord
```
Loadings:
```{r }
head(loadings)
```
Scores:
```{r }
head(scores)
```

# Cluster Analysis
Loadings from PCA was used in cluster analysis.
```{r}
ldfile<-read.csv(file = "Approach_I/PC_loadings.csv",header = T)
selectedData<-ldfile[,2:4]
row.names(selectedData)<-c("W60","W63","W67","W70","W73","W74","W78","W80","W81","W115",
                           "W116","W118")
selectedData
```

Elbow method to find optimal number of clusters:
```{r}
fviz_nbclust(selectedData, kmeans, method = "wss") +
  geom_vline(xintercept = 3, linetype = 2)+
  labs(subtitle = "Elbow method")
```

Using heirarchical clustering:
```{r}
distanceData = dist(selectedData, method="euclidean")
hclustData<-hclust(distanceData,method="ward.D")
plot(hclustData,main=" ",sub="Heirarchical clustering",xlab=" ")
rect.hclust(hclustData, k=3,border = "red")
mtext('Group A',side = 1,at = 3)
mtext('Group B',side = 1,at = 7)
mtext('Group C',side = 1,at = 10)
```

Using k-means clustering:
```{r}
kmeansData<-kmeans(selectedData,3) 
ClusterData<-kmeansData$cluster
```

Now, plotting loadings of PC1 against P2, PC2 against PC3, and PC3 against PC1
```{r}
palette(c("maroon","blue","dark green"))
plot(selectedData[,1],selectedData[,2],ylim=c(-0.3,0.6),xlim=c(-0.15,0.45),
     xlab="PC1",ylab="PC2",pch=19,cex=1,lty='solid',lwd=2,col= ClusterData)
text(selectedData[,c(1,2)],labels=rownames(selectedData),cex=1,pos=3,col= ClusterData)
legend('topright',legend=c("Group A","Group B","Group C"),col=c("maroon","blue","dark green"),pch=19,
       cex=1,bty="y")
grid()
```

```{r}
plot(selectedData[,2],selectedData[,3],ylim=c(-0.5,0.7),xlim=c(-0.3,0.6),
     xlab="PC2",ylab="PC3",pch=19,cex=1,lty='solid',lwd=2,col= ClusterData)
text(selectedData[,c(2,3)],labels=rownames(selectedData),cex=1,pos=3,col= ClusterData)
legend('topright',legend=c("Group A","Group B","Group C"),col=c("maroon","blue","dark green"),pch=19,
       cex=1,bty="y")
```

```{r}
plot(selectedData[,1],selectedData[,3],ylim=c(-0.5,0.6),xlim=c(-0.1,0.5),
     xlab="PC1",ylab="PC3",pch=19,cex=1,lty='solid',lwd=2,col= ClusterData)
text(selectedData[,c(1,3)],labels=rownames(selectedData),cex=1,pos=3,col= ClusterData)
legend('topright',legend=c("Group A","Group B","Group C"),col=c("red","blue","dark green"),pch=19,
       cex=1,bty="y")
```

# References
